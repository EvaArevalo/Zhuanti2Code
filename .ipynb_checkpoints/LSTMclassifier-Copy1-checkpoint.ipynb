{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM classifier for abusive/sarcastic language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from Preprocessing import config\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectToMongoDB(collection_name):\n",
    "    client = MongoClient(config.MONGODB['hostname'], config.MONGODB['port'])\n",
    "    db = client[config.MONGODB['db']]\n",
    "    collection = db[config.MONGODB[collection_name]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetsFromMongoDB(collection_name):\n",
    "\t''' mongodb to pandas dataframe, export to csv and return'''\n",
    "    connectToMongoDB(collection_name)\n",
    "\tresults=collection.find()\n",
    "\t#strip and reshuflle\n",
    "\tdf =  pd.DataFrame(list(results))\n",
    "\tdf=df[['label','text']]\n",
    "\tdf=df.reindex(np.random.permutation(df.index))\n",
    "    filename = collection_name +'.csv'\n",
    "\tdf.to_csv(filename,encoding='utf-8-sig')\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetsFromCsv():\n",
    "\t'''import csv, reshuffle and return it'''\n",
    "\tdf=pd.read_csv('sarcasm_and_news_dataset.csv')\n",
    "\tdf=df.reindex(np.random.permutation(df.index))\n",
    "\treturn df[['label','text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=getDatasetsFromCsv()\n",
    "train,test = train_test_split(data,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "embedding_dim = 128\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get labels, split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ['sarcasm' 'fact']\n",
      "text ['A la  Liga casi lo sancionan por parar el balón con el trasero y por los pases de taquito que incitaron al rival <hashtags>'\n",
      " 'EP Bin Laden declarará la guerra a Musharraf en un nuevo vídeo: El líder de la red Al Qaeda, Osama bin .. <link>'\n",
      " 'Le dije \"Hola\" y se desconectó. Creo que le dio un infarto de la emoción. <hashtags>'\n",
      " ...\n",
      " 'El derrumbe de una fachada deja cuatro heridos en Alcalá de Henares: Un \"derrumbe espontáneo\" en la facha.. <link>'\n",
      " 'Ilianise,Julieta y yo tenemos la suerte mas cabrona del mundo. <hashtags>'\n",
      " 'FC Barcelona tenemos competencia, ya no somos los unicos que compramos arbitros. <hashtags>']\n",
      "(17592, 38) (17592, 2)\n",
      "(4332, 38) (4332, 2)\n",
      "(4333, 38) (4333, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['label']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.33, \n",
    "    random_state=42)\n",
    "\n",
    "validation_size = math.ceil(X_test.shape[0]/2)\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "\n",
    "#Get shapes\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "print(X_validate.shape,Y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=None\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 56s - loss: 0.1207 - acc: 0.9528\n",
      "Epoch 2/10\n",
      " - 55s - loss: 0.0561 - acc: 0.9795\n",
      "Epoch 3/10\n",
      " - 52s - loss: 0.0444 - acc: 0.9833\n",
      "Epoch 4/10\n",
      " - 49s - loss: 0.0363 - acc: 0.9868\n",
      "Epoch 5/10\n",
      " - 52s - loss: 0.0313 - acc: 0.9895\n",
      "Epoch 6/10\n",
      " - 58s - loss: 0.0283 - acc: 0.9907\n",
      "Epoch 7/10\n",
      " - 49s - loss: 0.0243 - acc: 0.9912\n",
      "Epoch 8/10\n",
      " - 48s - loss: 0.0208 - acc: 0.9928\n",
      "Epoch 9/10\n",
      " - 47s - loss: 0.0222 - acc: 0.9921\n",
      "Epoch 10/10\n",
      " - 46s - loss: 0.0186 - acc: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae38e6e6d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.07\n",
      "acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Accuracy 98.02904564315352 %\n",
      "Negative Accuracy 97.83783783783784 %\n",
      "1890\n",
      "1928\n",
      "2353\n",
      "2405\n"
     ]
    }
   ],
   "source": [
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and get results, different embedding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c258491377df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSpatialDropout1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "#1000 features\n",
    "max_features = 1000\n",
    "embedding_dim = 128\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 78s - loss: 0.1174 - acc: 0.9549\n",
      "Epoch 2/10\n",
      " - 74s - loss: 0.0572 - acc: 0.9796\n",
      "Epoch 3/10\n",
      " - 72s - loss: 0.0440 - acc: 0.9840\n",
      "Epoch 4/10\n",
      " - 72s - loss: 0.0383 - acc: 0.9868\n",
      "Epoch 5/10\n",
      " - 73s - loss: 0.0320 - acc: 0.9889\n",
      "Epoch 6/10\n",
      " - 74s - loss: 0.0295 - acc: 0.9901\n",
      "Epoch 7/10\n",
      " - 66s - loss: 0.0248 - acc: 0.9910\n",
      "Epoch 8/10\n",
      " - 65s - loss: 0.0234 - acc: 0.9917\n",
      "Epoch 9/10\n",
      " - 69s - loss: 0.0184 - acc: 0.9937\n",
      "Epoch 10/10\n",
      " - 69s - loss: 0.0171 - acc: 0.9940\n",
      "score: 0.08\n",
      "acc: 0.98\n",
      "Positive Accuracy 97.82157676348547 %\n",
      "Negative Accuracy 98.17047817047818 %\n",
      "1886\n",
      "1928\n",
      "2361\n",
      "2405\n"
     ]
    }
   ],
   "source": [
    "#2000 features\n",
    "max_features = 2000\n",
    "embedding_dim = 128\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 79s - loss: 0.1280 - acc: 0.9508\n",
      "Epoch 2/10\n",
      " - 77s - loss: 0.0580 - acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 78s - loss: 0.0440 - acc: 0.9847\n",
      "Epoch 4/10\n",
      " - 75s - loss: 0.0352 - acc: 0.9874\n",
      "Epoch 5/10\n",
      " - 72s - loss: 0.0318 - acc: 0.9884\n",
      "Epoch 6/10\n",
      " - 78s - loss: 0.0290 - acc: 0.9901\n",
      "Epoch 7/10\n",
      " - 69s - loss: 0.0255 - acc: 0.9907\n",
      "Epoch 8/10\n",
      " - 77s - loss: 0.0226 - acc: 0.9910\n",
      "Epoch 9/10\n",
      " - 77s - loss: 0.0206 - acc: 0.9931\n",
      "Epoch 10/10\n",
      " - 77s - loss: 0.0174 - acc: 0.9940\n",
      "score: 0.08\n",
      "acc: 0.98\n",
      "Positive Accuracy 98.39211618257261 %\n",
      "Negative Accuracy 97.92099792099792 %\n",
      "1897\n",
      "1928\n",
      "2355\n",
      "2405\n"
     ]
    }
   ],
   "source": [
    "#4000 features\n",
    "max_features = 4000\n",
    "embedding_dim = 128\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 62s - loss: 0.1251 - acc: 0.9512\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.0572 - acc: 0.9791\n",
      "Epoch 3/10\n",
      " - 62s - loss: 0.0438 - acc: 0.9849\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.0372 - acc: 0.9862\n",
      "Epoch 5/10\n",
      " - 61s - loss: 0.0307 - acc: 0.9893\n",
      "Epoch 6/10\n",
      " - 61s - loss: 0.0289 - acc: 0.9897\n",
      "Epoch 7/10\n",
      " - 63s - loss: 0.0247 - acc: 0.9908\n",
      "Epoch 8/10\n",
      " - 63s - loss: 0.0235 - acc: 0.9917\n",
      "Epoch 9/10\n",
      " - 63s - loss: 0.0195 - acc: 0.9928\n",
      "Epoch 10/10\n",
      " - 62s - loss: 0.0184 - acc: 0.9931\n",
      "score: 0.08\n",
      "acc: 0.98\n",
      "Positive Accuracy 97.82157676348547 %\n",
      "Negative Accuracy 97.83783783783784 %\n",
      "1886\n",
      "1928\n",
      "2353\n",
      "2405\n"
     ]
    }
   ],
   "source": [
    "#8000 features\n",
    "max_features = 8000\n",
    "embedding_dim = 128\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16000 features\n",
    "max_features = 16000\n",
    "embedding_dim = 128\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 88s - loss: 0.1100 - acc: 0.9608\n",
      "Epoch 2/15\n",
      " - 85s - loss: 0.0511 - acc: 0.9809\n",
      "Epoch 3/15\n",
      " - 84s - loss: 0.0421 - acc: 0.9857\n",
      "Epoch 4/15\n",
      " - 84s - loss: 0.0337 - acc: 0.9883\n",
      "Epoch 5/15\n",
      " - 81s - loss: 0.0294 - acc: 0.9898\n",
      "Epoch 6/15\n",
      " - 86s - loss: 0.0252 - acc: 0.9908\n",
      "Epoch 7/15\n",
      " - 101s - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 8/15\n",
      " - 97s - loss: 0.0188 - acc: 0.9930\n",
      "Epoch 9/15\n",
      " - 103s - loss: 0.0168 - acc: 0.9944\n",
      "Epoch 10/15\n",
      " - 103s - loss: 0.0137 - acc: 0.9955\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-faa0a61b67bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\evaarevalo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#2000 features, embedding dim 256\n",
    "max_features = 2000\n",
    "embedding_dim = 256\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.09\n",
      "acc: 0.98\n",
      "Positive Accuracy 96.99170124481327 %\n",
      "Negative Accuracy 98.46153846153847 %\n",
      "1870\n",
      "1928\n",
      "2368\n",
      "2405\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 59s - loss: 0.1355 - acc: 0.9440\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.0646 - acc: 0.9760\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.0489 - acc: 0.9827\n",
      "Epoch 4/10\n",
      " - 59s - loss: 0.0405 - acc: 0.9852\n",
      "Epoch 5/10\n",
      " - 63s - loss: 0.0375 - acc: 0.9867\n",
      "Epoch 6/10\n",
      " - 60s - loss: 0.0353 - acc: 0.9875\n",
      "Epoch 7/10\n",
      " - 62s - loss: 0.0293 - acc: 0.9897\n",
      "Epoch 8/10\n",
      " - 56s - loss: 0.0278 - acc: 0.9906\n",
      "Epoch 9/10\n",
      " - 60s - loss: 0.0250 - acc: 0.9915\n",
      "Epoch 10/10\n",
      " - 57s - loss: 0.0227 - acc: 0.9922\n",
      "score: 0.09\n",
      "acc: 0.97\n",
      "Positive Accuracy 95.33195020746888 %\n",
      "Negative Accuracy 98.54469854469855 %\n",
      "1838\n",
      "1928\n",
      "2370\n",
      "2405\n"
     ]
    }
   ],
   "source": [
    "#4000 features, embedding dim 64\n",
    "max_features = 4000\n",
    "embedding_dim = 64\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "positive_correct = 0\n",
    "negative_correct = 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "\n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            negative_correct += 1\n",
    "        else:\n",
    "            positive_correct += 1\n",
    "\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        negative_count += 1\n",
    "    else:\n",
    "        positive_count += 1\n",
    "\n",
    "print(\"Positive Accuracy\", positive_correct/positive_count*100, \"%\")\n",
    "print(\"Negative Accuracy\", negative_correct/negative_count*100, \"%\")\n",
    "print(positive_correct)\n",
    "print(positive_count)\n",
    "print(negative_correct)\n",
    "print(negative_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 /10\n",
      "Epoch 1/10\n",
      " - 103s - loss: 0.1408 - acc: 0.9432\n",
      "Epoch 2/10\n",
      " - 97s - loss: 0.0616 - acc: 0.9773\n",
      "Epoch 3/10\n",
      " - 97s - loss: 0.0478 - acc: 0.9835\n",
      "Epoch 4/10\n",
      " - 97s - loss: 0.0419 - acc: 0.9847\n",
      "Epoch 5/10\n",
      " - 97s - loss: 0.0366 - acc: 0.9869\n",
      "Epoch 6/10\n",
      " - 87s - loss: 0.0318 - acc: 0.9891\n",
      "Epoch 7/10\n",
      " - 86s - loss: 0.0314 - acc: 0.9893\n",
      "Epoch 8/10\n",
      " - 89s - loss: 0.0272 - acc: 0.9907\n",
      "Epoch 9/10\n",
      " - 94s - loss: 0.0249 - acc: 0.9914\n",
      "Epoch 10/10\n",
      " - 99s - loss: 0.0232 - acc: 0.9919\n",
      "score: 0.08\n",
      "acc: 0.98\n",
      "Running Fold 2 /10\n",
      "Epoch 1/10\n",
      " - 111s - loss: 0.1367 - acc: 0.9449\n",
      "Epoch 2/10\n",
      " - 105s - loss: 0.0601 - acc: 0.9780\n",
      "Epoch 3/10\n",
      " - 105s - loss: 0.0487 - acc: 0.9822\n",
      "Epoch 4/10\n",
      " - 104s - loss: 0.0398 - acc: 0.9868\n",
      "Epoch 5/10\n",
      " - 104s - loss: 0.0361 - acc: 0.9875\n",
      "Epoch 6/10\n",
      " - 105s - loss: 0.0326 - acc: 0.9887\n",
      "Epoch 7/10\n",
      " - 105s - loss: 0.0290 - acc: 0.9889\n",
      "Epoch 8/10\n",
      " - 106s - loss: 0.0281 - acc: 0.9891\n",
      "Epoch 9/10\n",
      " - 107s - loss: 0.0247 - acc: 0.9914\n",
      "Epoch 10/10\n",
      " - 111s - loss: 0.0225 - acc: 0.9924\n",
      "score: 0.07\n",
      "acc: 0.98\n",
      "Running Fold 3 /10\n",
      "Epoch 1/10\n",
      " - 133s - loss: 0.1343 - acc: 0.9467\n",
      "Epoch 2/10\n",
      " - 123s - loss: 0.0616 - acc: 0.9781\n",
      "Epoch 3/10\n",
      " - 113s - loss: 0.0475 - acc: 0.9829\n",
      "Epoch 4/10\n",
      " - 115s - loss: 0.0387 - acc: 0.9861\n",
      "Epoch 5/10\n",
      " - 115s - loss: 0.0348 - acc: 0.9876\n",
      "Epoch 6/10\n",
      " - 109s - loss: 0.0318 - acc: 0.9893\n",
      "Epoch 7/10\n",
      " - 113s - loss: 0.0299 - acc: 0.9887\n",
      "Epoch 8/10\n",
      " - 100s - loss: 0.0255 - acc: 0.9915\n",
      "Epoch 9/10\n",
      " - 114s - loss: 0.0246 - acc: 0.9910\n",
      "Epoch 10/10\n",
      " - 109s - loss: 0.0225 - acc: 0.9922\n",
      "score: 0.07\n",
      "acc: 0.98\n",
      "Running Fold 4 /10\n",
      "Epoch 1/10\n",
      " - 130s - loss: 0.1349 - acc: 0.9447\n",
      "Epoch 2/10\n",
      " - 113s - loss: 0.0608 - acc: 0.9785\n",
      "Epoch 3/10\n",
      " - 117s - loss: 0.0493 - acc: 0.9819\n",
      "Epoch 4/10\n",
      " - 114s - loss: 0.0414 - acc: 0.9860\n",
      "Epoch 5/10\n",
      " - 123s - loss: 0.0383 - acc: 0.9876\n",
      "Epoch 6/10\n",
      " - 116s - loss: 0.0334 - acc: 0.9881\n",
      "Epoch 7/10\n",
      " - 118s - loss: 0.0317 - acc: 0.9882\n",
      "Epoch 8/10\n",
      " - 117s - loss: 0.0278 - acc: 0.9905\n",
      "Epoch 9/10\n",
      " - 117s - loss: 0.0258 - acc: 0.9910\n",
      "Epoch 10/10\n",
      " - 128s - loss: 0.0229 - acc: 0.9925\n",
      "score: 0.08\n",
      "acc: 0.98\n",
      "Running Fold 5 /10\n",
      "Epoch 1/10\n",
      " - 132s - loss: 0.1385 - acc: 0.9422\n",
      "Epoch 2/10\n",
      " - 124s - loss: 0.0603 - acc: 0.9785\n",
      "Epoch 3/10\n",
      " - 132s - loss: 0.0471 - acc: 0.9824\n",
      "Epoch 4/10\n",
      " - 135s - loss: 0.0420 - acc: 0.9843\n",
      "Epoch 5/10\n",
      " - 134s - loss: 0.0383 - acc: 0.9867\n",
      "Epoch 6/10\n",
      " - 137s - loss: 0.0315 - acc: 0.9895\n",
      "Epoch 7/10\n",
      " - 122s - loss: 0.0298 - acc: 0.9891\n",
      "Epoch 8/10\n",
      " - 118s - loss: 0.0261 - acc: 0.9915\n",
      "Epoch 9/10\n",
      " - 118s - loss: 0.0241 - acc: 0.9914\n",
      "Epoch 10/10\n",
      " - 122s - loss: 0.0238 - acc: 0.9913\n",
      "score: 0.07\n",
      "acc: 0.98\n",
      "Running Fold 6 /10\n",
      "Epoch 1/10\n",
      " - 143s - loss: 0.1376 - acc: 0.9515\n",
      "Epoch 2/10\n",
      " - 140s - loss: 0.0627 - acc: 0.9775\n",
      "Epoch 3/10\n",
      " - 130s - loss: 0.0496 - acc: 0.9815\n",
      "Epoch 4/10\n",
      " - 138s - loss: 0.0406 - acc: 0.9854\n",
      "Epoch 5/10\n",
      " - 136s - loss: 0.0373 - acc: 0.9869\n",
      "Epoch 6/10\n",
      " - 131s - loss: 0.0344 - acc: 0.9877\n",
      "Epoch 7/10\n",
      " - 130s - loss: 0.0293 - acc: 0.9898\n",
      "Epoch 8/10\n",
      " - 137s - loss: 0.0287 - acc: 0.9891\n",
      "Epoch 9/10\n",
      " - 126s - loss: 0.0257 - acc: 0.9906\n",
      "Epoch 10/10\n",
      " - 131s - loss: 0.0227 - acc: 0.9919\n",
      "score: 0.07\n",
      "acc: 0.98\n",
      "Running Fold 7 /10\n",
      "Epoch 1/10\n",
      " - 165s - loss: 0.1376 - acc: 0.9443\n",
      "Epoch 2/10\n",
      " - 148s - loss: 0.0633 - acc: 0.9775\n",
      "Epoch 3/10\n",
      " - 155s - loss: 0.0488 - acc: 0.9820\n",
      "Epoch 4/10\n",
      " - 151s - loss: 0.0410 - acc: 0.9847\n",
      "Epoch 5/10\n",
      " - 166s - loss: 0.0349 - acc: 0.9872\n",
      "Epoch 6/10\n",
      " - 154s - loss: 0.0321 - acc: 0.9887\n",
      "Epoch 7/10\n",
      " - 151s - loss: 0.0289 - acc: 0.9898\n",
      "Epoch 8/10\n",
      " - 147s - loss: 0.0267 - acc: 0.9910\n",
      "Epoch 9/10\n",
      " - 149s - loss: 0.0265 - acc: 0.9914\n",
      "Epoch 10/10\n",
      " - 154s - loss: 0.0235 - acc: 0.9916\n",
      "score: 0.06\n",
      "acc: 0.98\n",
      "Running Fold 8 /10\n",
      "Epoch 1/10\n",
      " - 154s - loss: 0.1368 - acc: 0.9451\n",
      "Epoch 2/10\n",
      " - 153s - loss: 0.0596 - acc: 0.9787\n",
      "Epoch 3/10\n",
      " - 146s - loss: 0.0520 - acc: 0.9812\n",
      "Epoch 4/10\n",
      " - 145s - loss: 0.0443 - acc: 0.9841\n",
      "Epoch 5/10\n",
      " - 151s - loss: 0.0362 - acc: 0.9869\n",
      "Epoch 6/10\n",
      " - 166s - loss: 0.0335 - acc: 0.9882\n",
      "Epoch 7/10\n",
      " - 158s - loss: 0.0298 - acc: 0.9890\n",
      "Epoch 8/10\n",
      " - 168s - loss: 0.0282 - acc: 0.9897\n",
      "Epoch 9/10\n",
      " - 165s - loss: 0.0268 - acc: 0.9906\n",
      "Epoch 10/10\n",
      " - 163s - loss: 0.0234 - acc: 0.9918\n",
      "score: 0.08\n",
      "acc: 0.98\n",
      "Running Fold 9 /10\n",
      "Epoch 1/10\n",
      " - 167s - loss: 0.1353 - acc: 0.9442\n",
      "Epoch 2/10\n",
      " - 167s - loss: 0.0628 - acc: 0.9778\n",
      "Epoch 3/10\n",
      " - 169s - loss: 0.0483 - acc: 0.9822\n",
      "Epoch 4/10\n",
      " - 195s - loss: 0.0416 - acc: 0.9853\n",
      "Epoch 5/10\n",
      " - 183s - loss: 0.0391 - acc: 0.9870\n",
      "Epoch 6/10\n",
      " - 163s - loss: 0.0323 - acc: 0.9885\n",
      "Epoch 7/10\n",
      " - 160s - loss: 0.0321 - acc: 0.9892\n",
      "Epoch 8/10\n",
      " - 161s - loss: 0.0291 - acc: 0.9892\n",
      "Epoch 9/10\n",
      " - 162s - loss: 0.0247 - acc: 0.9911\n",
      "Epoch 10/10\n",
      " - 164s - loss: 0.0241 - acc: 0.9921\n",
      "score: 0.07\n",
      "acc: 0.98\n",
      "Running Fold 10 /10\n",
      "Epoch 1/10\n",
      " - 177s - loss: 0.1364 - acc: 0.9459\n",
      "Epoch 2/10\n",
      " - 172s - loss: 0.0611 - acc: 0.9790\n",
      "Epoch 3/10\n",
      " - 192s - loss: 0.0491 - acc: 0.9831\n",
      "Epoch 4/10\n",
      " - 176s - loss: 0.0415 - acc: 0.9861\n",
      "Epoch 5/10\n",
      " - 169s - loss: 0.0369 - acc: 0.9864\n",
      "Epoch 6/10\n",
      " - 174s - loss: 0.0328 - acc: 0.9890\n",
      "Epoch 7/10\n",
      " - 172s - loss: 0.0291 - acc: 0.9904\n",
      "Epoch 8/10\n",
      " - 170s - loss: 0.0295 - acc: 0.9892\n",
      "Epoch 9/10\n",
      " - 168s - loss: 0.0254 - acc: 0.9904\n",
      "Epoch 10/10\n",
      " - 172s - loss: 0.0239 - acc: 0.9919\n",
      "score: 0.07\n",
      "acc: 0.98\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ... 1 0 0], n_folds=10, shuffle=True, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "max_features = 4000\n",
    "embedding_dim = 64\n",
    "lstm_out_dim = 196\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activa tion='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "n_folds = 10\n",
    "#print(Y.shape)\n",
    "#print(Y)\n",
    "Y_reshaped=[]\n",
    "for item in Y:\n",
    "    Y_reshaped.append(item[0])\n",
    "    #print(item[0])\n",
    "skf = StratifiedKFold(Y_reshaped, n_folds=n_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train, test) in enumerate(skf):\n",
    "        print (\"Running Fold\", i+1, \"/10\",)\n",
    "        model=None\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(max_features, embedding_dim,input_length=X.shape[1]))\n",
    "        model.add(SpatialDropout1D(0.4))\n",
    "        model.add(LSTM(lstm_out_dim, dropout=0.2,recurrent_dropout=0.2))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        print(model)\n",
    "        model.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=2)\n",
    "        score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "        print(\"score: %.2f\" % (score))\n",
    "        print(\"acc: %.2f\" % (acc))\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Running Fold 1 /10\n",
    "Epoch 1/10\n",
    " - 103s - loss: 0.1408 - acc: 0.9432\n",
    "Epoch 2/10\n",
    " - 97s - loss: 0.0616 - acc: 0.9773\n",
    "Epoch 3/10\n",
    " - 97s - loss: 0.0478 - acc: 0.9835\n",
    "Epoch 4/10\n",
    " - 97s - loss: 0.0419 - acc: 0.9847\n",
    "Epoch 5/10\n",
    " - 97s - loss: 0.0366 - acc: 0.9869\n",
    "Epoch 6/10\n",
    " - 87s - loss: 0.0318 - acc: 0.9891\n",
    "Epoch 7/10\n",
    " - 86s - loss: 0.0314 - acc: 0.9893\n",
    "Epoch 8/10\n",
    " - 89s - loss: 0.0272 - acc: 0.9907\n",
    "Epoch 9/10\n",
    " - 94s - loss: 0.0249 - acc: 0.9914\n",
    "Epoch 10/10\n",
    " - 99s - loss: 0.0232 - acc: 0.9919\n",
    "score: 0.08\n",
    "acc: 0.98\n",
    "Running Fold 2 /10\n",
    "Epoch 1/10\n",
    " - 111s - loss: 0.1367 - acc: 0.9449\n",
    "Epoch 2/10\n",
    " - 105s - loss: 0.0601 - acc: 0.9780\n",
    "Epoch 3/10\n",
    " - 105s - loss: 0.0487 - acc: 0.9822\n",
    "Epoch 4/10\n",
    " - 104s - loss: 0.0398 - acc: 0.9868\n",
    "Epoch 5/10\n",
    " - 104s - loss: 0.0361 - acc: 0.9875\n",
    "Epoch 6/10\n",
    " - 105s - loss: 0.0326 - acc: 0.9887\n",
    "Epoch 7/10\n",
    " - 105s - loss: 0.0290 - acc: 0.9889\n",
    "Epoch 8/10\n",
    " - 106s - loss: 0.0281 - acc: 0.9891\n",
    "Epoch 9/10\n",
    " - 107s - loss: 0.0247 - acc: 0.9914\n",
    "Epoch 10/10\n",
    " - 111s - loss: 0.0225 - acc: 0.9924\n",
    "score: 0.07\n",
    "acc: 0.98\n",
    "Running Fold 3 /10\n",
    "Epoch 1/10\n",
    " - 133s - loss: 0.1343 - acc: 0.9467\n",
    "Epoch 2/10\n",
    " - 123s - loss: 0.0616 - acc: 0.9781\n",
    "Epoch 3/10\n",
    " - 113s - loss: 0.0475 - acc: 0.9829\n",
    "Epoch 4/10\n",
    " - 115s - loss: 0.0387 - acc: 0.9861\n",
    "Epoch 5/10\n",
    " - 115s - loss: 0.0348 - acc: 0.9876\n",
    "Epoch 6/10\n",
    " - 109s - loss: 0.0318 - acc: 0.9893\n",
    "Epoch 7/10\n",
    " - 113s - loss: 0.0299 - acc: 0.9887\n",
    "Epoch 8/10\n",
    " - 100s - loss: 0.0255 - acc: 0.9915\n",
    "Epoch 9/10\n",
    " - 114s - loss: 0.0246 - acc: 0.9910\n",
    "Epoch 10/10\n",
    " - 109s - loss: 0.0225 - acc: 0.9922\n",
    "score: 0.07\n",
    "acc: 0.98\n",
    "Running Fold 4 /10\n",
    "Epoch 1/10\n",
    " - 130s - loss: 0.1349 - acc: 0.9447\n",
    "Epoch 2/10\n",
    " - 113s - loss: 0.0608 - acc: 0.9785\n",
    "Epoch 3/10\n",
    " - 117s - loss: 0.0493 - acc: 0.9819\n",
    "Epoch 4/10\n",
    " - 114s - loss: 0.0414 - acc: 0.9860\n",
    "Epoch 5/10\n",
    " - 123s - loss: 0.0383 - acc: 0.9876\n",
    "Epoch 6/10\n",
    " - 116s - loss: 0.0334 - acc: 0.9881\n",
    "Epoch 7/10\n",
    " - 118s - loss: 0.0317 - acc: 0.9882\n",
    "Epoch 8/10\n",
    " - 117s - loss: 0.0278 - acc: 0.9905\n",
    "Epoch 9/10\n",
    " - 117s - loss: 0.0258 - acc: 0.9910\n",
    "Epoch 10/10\n",
    " - 128s - loss: 0.0229 - acc: 0.9925\n",
    "score: 0.08\n",
    "acc: 0.98\n",
    "Running Fold 5 /10\n",
    "Epoch 1/10\n",
    " - 132s - loss: 0.1385 - acc: 0.9422\n",
    "Epoch 2/10\n",
    " - 124s - loss: 0.0603 - acc: 0.9785\n",
    "Epoch 3/10\n",
    " - 132s - loss: 0.0471 - acc: 0.9824\n",
    "Epoch 4/10\n",
    " - 135s - loss: 0.0420 - acc: 0.9843\n",
    "Epoch 5/10\n",
    " - 134s - loss: 0.0383 - acc: 0.9867\n",
    "Epoch 6/10\n",
    " - 137s - loss: 0.0315 - acc: 0.9895\n",
    "Epoch 7/10\n",
    " - 122s - loss: 0.0298 - acc: 0.9891\n",
    "Epoch 8/10\n",
    " - 118s - loss: 0.0261 - acc: 0.9915\n",
    "Epoch 9/10\n",
    " - 118s - loss: 0.0241 - acc: 0.9914\n",
    "Epoch 10/10\n",
    " - 122s - loss: 0.0238 - acc: 0.9913\n",
    "score: 0.07\n",
    "acc: 0.98\n",
    "Running Fold 6 /10\n",
    "Epoch 1/10\n",
    " - 143s - loss: 0.1376 - acc: 0.9515\n",
    "Epoch 2/10\n",
    " - 140s - loss: 0.0627 - acc: 0.9775\n",
    "Epoch 3/10\n",
    " - 130s - loss: 0.0496 - acc: 0.9815\n",
    "Epoch 4/10\n",
    " - 138s - loss: 0.0406 - acc: 0.9854\n",
    "Epoch 5/10\n",
    " - 136s - loss: 0.0373 - acc: 0.9869\n",
    "Epoch 6/10\n",
    " - 131s - loss: 0.0344 - acc: 0.9877\n",
    "Epoch 7/10\n",
    " - 130s - loss: 0.0293 - acc: 0.9898\n",
    "Epoch 8/10\n",
    " - 137s - loss: 0.0287 - acc: 0.9891\n",
    "Epoch 9/10\n",
    " - 126s - loss: 0.0257 - acc: 0.9906\n",
    "Epoch 10/10\n",
    " - 131s - loss: 0.0227 - acc: 0.9919\n",
    "score: 0.07\n",
    "acc: 0.98\n",
    "Running Fold 7 /10\n",
    "Epoch 1/10\n",
    " - 165s - loss: 0.1376 - acc: 0.9443\n",
    "Epoch 2/10\n",
    " - 148s - loss: 0.0633 - acc: 0.9775\n",
    "Epoch 3/10\n",
    " - 155s - loss: 0.0488 - acc: 0.9820\n",
    "Epoch 4/10\n",
    " - 151s - loss: 0.0410 - acc: 0.9847\n",
    "Epoch 5/10\n",
    " - 166s - loss: 0.0349 - acc: 0.9872\n",
    "Epoch 6/10\n",
    " - 154s - loss: 0.0321 - acc: 0.9887\n",
    "Epoch 7/10\n",
    " - 151s - loss: 0.0289 - acc: 0.9898\n",
    "Epoch 8/10\n",
    " - 147s - loss: 0.0267 - acc: 0.9910\n",
    "Epoch 9/10\n",
    " - 149s - loss: 0.0265 - acc: 0.9914\n",
    "Epoch 10/10\n",
    " - 154s - loss: 0.0235 - acc: 0.9916\n",
    "score: 0.06\n",
    "acc: 0.98\n",
    "Running Fold 8 /10\n",
    "Epoch 1/10\n",
    " - 154s - loss: 0.1368 - acc: 0.9451\n",
    "Epoch 2/10\n",
    " - 153s - loss: 0.0596 - acc: 0.9787\n",
    "Epoch 3/10\n",
    " - 146s - loss: 0.0520 - acc: 0.9812\n",
    "Epoch 4/10\n",
    " - 145s - loss: 0.0443 - acc: 0.9841\n",
    "Epoch 5/10\n",
    " - 151s - loss: 0.0362 - acc: 0.9869\n",
    "Epoch 6/10\n",
    " - 166s - loss: 0.0335 - acc: 0.9882\n",
    "Epoch 7/10\n",
    " - 158s - loss: 0.0298 - acc: 0.9890\n",
    "Epoch 8/10\n",
    " - 168s - loss: 0.0282 - acc: 0.9897\n",
    "Epoch 9/10\n",
    " - 165s - loss: 0.0268 - acc: 0.9906\n",
    "Epoch 10/10\n",
    " - 163s - loss: 0.0234 - acc: 0.9918\n",
    "score: 0.08\n",
    "acc: 0.98\n",
    "Running Fold 9 /10\n",
    "Epoch 1/10\n",
    " - 167s - loss: 0.1353 - acc: 0.9442\n",
    "Epoch 2/10\n",
    " - 167s - loss: 0.0628 - acc: 0.9778\n",
    "Epoch 3/10\n",
    " - 169s - loss: 0.0483 - acc: 0.9822\n",
    "Epoch 4/10\n",
    " - 195s - loss: 0.0416 - acc: 0.9853\n",
    "Epoch 5/10\n",
    " - 183s - loss: 0.0391 - acc: 0.9870\n",
    "Epoch 6/10\n",
    " - 163s - loss: 0.0323 - acc: 0.9885\n",
    "Epoch 7/10\n",
    " - 160s - loss: 0.0321 - acc: 0.9892\n",
    "Epoch 8/10\n",
    " - 161s - loss: 0.0291 - acc: 0.9892\n",
    "Epoch 9/10\n",
    " - 162s - loss: 0.0247 - acc: 0.9911\n",
    "Epoch 10/10\n",
    " - 164s - loss: 0.0241 - acc: 0.9921\n",
    "score: 0.07\n",
    "acc: 0.98\n",
    "Running Fold 10 /10\n",
    "Epoch 1/10\n",
    " - 177s - loss: 0.1364 - acc: 0.9459\n",
    "Epoch 2/10\n",
    " - 172s - loss: 0.0611 - acc: 0.9790\n",
    "Epoch 3/10\n",
    " - 192s - loss: 0.0491 - acc: 0.9831\n",
    "Epoch 4/10\n",
    " - 176s - loss: 0.0415 - acc: 0.9861\n",
    "Epoch 5/10\n",
    " - 169s - loss: 0.0369 - acc: 0.9864\n",
    "Epoch 6/10\n",
    " - 174s - loss: 0.0328 - acc: 0.9890\n",
    "Epoch 7/10\n",
    " - 172s - loss: 0.0291 - acc: 0.9904\n",
    "Epoch 8/10\n",
    " - 170s - loss: 0.0295 - acc: 0.9892\n",
    "Epoch 9/10\n",
    " - 168s - loss: 0.0254 - acc: 0.9904\n",
    "Epoch 10/10\n",
    " - 172s - loss: 0.0239 - acc: 0.9919\n",
    "score: 0.07\n",
    "acc: 0.98\n",
    "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ... 1 0 0], n_folds=10, shuffle=True, random_state=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
